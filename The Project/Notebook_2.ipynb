{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a18f20-40c8-443a-a0e1-c162b5039461",
   "metadata": {},
   "source": [
    "### Persistent vector storage + Better QA (Question - Answer) Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5abade-ebd3-46aa-991b-3cc47eaf35f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4936d1e-5566-40ed-99d9-54bedc88a1a0",
   "metadata": {},
   "source": [
    "### Step 1 : Ingesting PDFs from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630d328-cd5d-4bb7-9786-9eafdcd3b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 15 total pages/chunks from 3 PDF files:\n",
      " - Leave-Policy.pdf\n",
      " - posh-policy.pdf\n",
      " - Salary_Policy.pdf\n"
     ]
    }
   ],
   "source": [
    "# Folder where PDFs are stored\n",
    "pdf_folder = \"policies\"\n",
    "\n",
    "documents = []\n",
    "loaded_files = []\n",
    "\n",
    "for file in os.listdir(pdf_folder):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_folder, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            # Attach metadata (source filename)\n",
    "            d.metadata[\"source\"] = file\n",
    "        documents.extend(docs)\n",
    "        loaded_files.append(file)\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} total pages/chunks from {len(loaded_files)} PDF files:\")\n",
    "for f in loaded_files:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510752b-b5f1-452d-b5f7-6a8a2849a672",
   "metadata": {},
   "source": [
    "### Step 2 : Splitting Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9c2909-2f6c-4153-aecd-8c9c971e52bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 37 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split into smaller chunks (for token efficiency)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✅ Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c98624-fcb8-46fe-9b78-873ffc61d546",
   "metadata": {},
   "source": [
    "### Step 3 : Embedding and Vector Storage (local ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8f3838-7bf0-4a81-b145-de8de1f7727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.9)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "Successfully installed tokenizers-0.21.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f31507-be0b-473d-9a19-fa837f941cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore created & persisted to disk (using HuggingFace embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Free alternative embeddings using SentenceTransformers\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Create embeddings using a small, fast model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build Chroma vectorstore\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_store\"  # This creates a directory by this name \n",
    ")\n",
    "\n",
    "vectordb.persist()\n",
    "print(\"✅ Vectorstore created & persisted to disk (using HuggingFace embeddings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90982472-c73a-4de1-b026-0e1615f75ef8",
   "metadata": {},
   "source": [
    "### Step 4 : Loading the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec9357f-5a05-4c81-88a4-175002453a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\", \n",
    "    api_key=groq_api_key,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab9ef1-097b-4621-ab63-84eec6a66c92",
   "metadata": {},
   "source": [
    "### Step 5 : Build Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61020a44-9fb7-4927-8263-3dbc47490d16",
   "metadata": {},
   "source": [
    "- Retriever fetches top-2 most relevant chunks.\n",
    "- Conversational chain allows multi-turn Q&A with context retention.\n",
    "- chat_history stores previous Q&A turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958b0483-d6bd-4a3e-9da5-55365b952ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f5e66-c5a9-4bb3-bc10-f283069fe7c3",
   "metadata": {},
   "source": [
    "### Step 6 : Interactive QnA loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c1d602-eb88-4fa5-b890-eb13932739b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What are POSH Policy guidelines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Based on the provided context, the POSH Policy guidelines are as follows:\n",
      "\n",
      "1. **Purpose**: To create and maintain a safe work environment, free from sexual harassment and discrimination for all employees.\n",
      "2. **Scope**: BBIL SYSTEMS aims to adopt a zero-tolerance attitude against any kind of sexual harassment or discrimination caused by any employee towards any other person, including employees, clients, vendors, and contractors, in company premises or elsewhere in India or abroad.\n",
      "3. **Applicability**: The policy applies to all employees of BBIL SYSTEMS, including those hired on a permanent, temporary, contracted, or part-time basis, directly or indirectly, or through a vendor organization.\n",
      "4. **Definition of Employee**: An employee of BBIL SYSTEMS includes anyone carrying out work on behalf of the company, regardless of their employment status or basis.\n",
      "\n",
      "These guidelines are based on the \"The Sexual harassment of women at workplace (prevention, prohibition & redressal) Act, 2013.\"\n",
      "\n",
      "Sources:\n",
      "- posh-policy.pdf\n",
      "- posh-policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  How many Earned Leaves do I get in one year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Unfortunately, the given context does not specify the number of Earned Leaves you get in one year. It only mentions that if you are unable to use all of your accrued Earned Leave during a calendar year, you may elect to carry forward any accrued but unused Earned leave into the next calendar year, subject to the maximum leave of 45 days.\n",
      "\n",
      "Sources:\n",
      "- Leave-Policy.pdf\n",
      "- Leave-Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What is casual leave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Casual leave is a type of leave that an employee can take for personal or miscellaneous reasons, such as a family event, a personal appointment, or a sudden need to attend to a personal matter. It is usually taken on short notice and is not related to illness or injury.\n",
      "\n",
      "Sources:\n",
      "- Leave-Policy.pdf\n",
      "- Leave-Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What do you mean by Scope and purpose\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Based on the provided context, it appears that the Scope and purpose are related to the disclosure of information about IEnova and its affiliates, subsidiaries, and business relationships.\n",
      "\n",
      "The Scope seems to refer to the categories of entities that are included in the disclosure, such as:\n",
      "\n",
      "* Individuals mentioned in conditions a) to c)\n",
      "* Partners or co-owners of these individuals\n",
      "* Companies that are part of a business group or consortium to which IEnova belongs\n",
      "* Companies over which IEnova has control or significant influence\n",
      "\n",
      "The Purpose seems to be to provide transparency and disclosure about the business relationships and affiliations of IEnova and its related entities. This may be for regulatory, compliance, or reporting purposes.\n",
      "\n",
      "Sources:\n",
      "- Salary_Policy.pdf\n",
      "- Salary_Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  Can you describe the scope and functions in depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Based on the provided context, here's a detailed explanation of the scope and purpose of the POSH Policy guidelines:\n",
      "\n",
      "**Purpose:**\n",
      "The primary purpose of the POSH Policy guidelines is to create and maintain a safe work environment that is free from sexual harassment and discrimination for all employees. The policy aims to establish guidelines as per the guidelines of \"The Sexual harassment of women at workplace (prevention, prohibition & redressal) Act, 2013.\"\n",
      "\n",
      "In simpler terms, the purpose of the POSH Policy is to ensure that all employees, regardless of their gender, feel safe and respected in the workplace. It aims to prevent and prohibit any form of sexual harassment or discrimination, and provide a framework for addressing and resolving such issues.\n",
      "\n",
      "**Scope:**\n",
      "The scope of the POSH Policy guidelines is broad and inclusive. BBIL SYSTEMS aims to adopt a zero-tolerance attitude towards any kind of sexual harassment or discrimination caused by any employee during their tenure in BBIL SYSTEMS. The policy applies to all employees of BBIL SYSTEMS, including:\n",
      "\n",
      "* Permanent employees\n",
      "* Temporary employees\n",
      "* Contracted employees\n",
      "* Retainer ship basis employees\n",
      "* Part-time employees\n",
      "* Employees hired directly or indirectly\n",
      "* Employees hired through vendor organizations\n",
      "\n",
      "The policy also extends to clients, vendors, and contractors in Company premises or elsewhere in India or abroad. This means that anyone who interacts with BBIL SYSTEMS, whether in person or remotely, is expected to adhere to the principles of the POSH Policy.\n",
      "\n",
      "In summary, the POSH Policy guidelines aim to create a safe and respectful work environment for all employees, clients, vendors, and contractors, and provide a framework for addressing and resolving any issues related to sexual harassment or discrimination.\n",
      "\n",
      "Sources:\n",
      "- posh-policy.pdf\n",
      "- posh-policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in (\"exit\", \"quit\"):\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        result = qa_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "        answer = result[\"answer\"]\n",
    "        sources = result[\"source_documents\"]\n",
    "\n",
    "        print(\"\\nAnswer:\")\n",
    "        print(answer)\n",
    "\n",
    "        print(\"\\nSources:\")\n",
    "        for src in sources:\n",
    "            print(f\"- {src.metadata.get('source')}\")\n",
    "\n",
    "        # Update chat history\n",
    "        chat_history.append((query, answer))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5555e-c559-4d3a-a864-cf6c008b4321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
