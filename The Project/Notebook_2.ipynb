{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a18f20-40c8-443a-a0e1-c162b5039461",
   "metadata": {},
   "source": [
    "### Persistent vector storage + Better QA (Question - Answer) Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5abade-ebd3-46aa-991b-3cc47eaf35f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4936d1e-5566-40ed-99d9-54bedc88a1a0",
   "metadata": {},
   "source": [
    "### Step 1 : Ingesting PDFs from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5630d328-cd5d-4bb7-9786-9eafdcd3b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 15 total pages/chunks from 3 PDF files:\n",
      " - Leave-Policy.pdf\n",
      " - posh-policy.pdf\n",
      " - Salary_Policy.pdf\n"
     ]
    }
   ],
   "source": [
    "# Folder where PDFs are stored\n",
    "pdf_folder = \"policies\"\n",
    "\n",
    "documents = []\n",
    "loaded_files = []\n",
    "\n",
    "for file in os.listdir(pdf_folder):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_folder, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            # Attach metadata (source filename)\n",
    "            d.metadata[\"source\"] = file\n",
    "        documents.extend(docs)\n",
    "        loaded_files.append(file)\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} total pages/chunks from {len(loaded_files)} PDF files:\")\n",
    "for f in loaded_files:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510752b-b5f1-452d-b5f7-6a8a2849a672",
   "metadata": {},
   "source": [
    "### Step 2 : Splitting Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9c2909-2f6c-4153-aecd-8c9c971e52bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 37 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split into smaller chunks (for token efficiency)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✅ Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c98624-fcb8-46fe-9b78-873ffc61d546",
   "metadata": {},
   "source": [
    "### Step 3 : Embedding and Vector Storage (local ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8f3838-7bf0-4a81-b145-de8de1f7727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saket.khopkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f31507-be0b-473d-9a19-fa837f941cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket.khopkar\\AppData\\Local\\Temp\\ipykernel_1612\\4032760243.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore created & persisted to disk (using HuggingFace embeddings)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket.khopkar\\AppData\\Local\\Temp\\ipykernel_1612\\4032760243.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# Free alternative embeddings using SentenceTransformers\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Create embeddings using a small, fast model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build Chroma vectorstore\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_store\"  # This creates a directory by this name \n",
    ")\n",
    "\n",
    "vectordb.persist()\n",
    "print(\"✅ Vectorstore created & persisted to disk (using HuggingFace embeddings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90982472-c73a-4de1-b026-0e1615f75ef8",
   "metadata": {},
   "source": [
    "### Step 4 : Loading the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec9357f-5a05-4c81-88a4-175002453a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\", \n",
    "    api_key=groq_api_key,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab9ef1-097b-4621-ab63-84eec6a66c92",
   "metadata": {},
   "source": [
    "### Step 5 : Build Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61020a44-9fb7-4927-8263-3dbc47490d16",
   "metadata": {},
   "source": [
    "- Retriever fetches top-2 most relevant chunks.\n",
    "- Conversational chain allows multi-turn Q&A with context retention.\n",
    "- chat_history stores previous Q&A turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958b0483-d6bd-4a3e-9da5-55365b952ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f5e66-c5a9-4bb3-bc10-f283069fe7c3",
   "metadata": {},
   "source": [
    "### Step 6 : Interactive QnA loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c1d602-eb88-4fa5-b890-eb13932739b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What are POSH Policy guidelines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You Asked:\n",
      "What are POSH Policy guidelines\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, the POSH Policy guidelines for BBIL SYSTEMS are as follows:\n",
      "\n",
      "1. **Purpose**: To create and maintain a safe work environment, free from sexual harassment and discrimination for all employees.\n",
      "2. **Scope**: The policy applies to all employees of BBIL SYSTEMS, including those hired on a permanent, temporary, contracted, or part-time basis, directly or indirectly, or through a vendor organization.\n",
      "3. **Applicability**: The policy applies to all employees of BBIL SYSTEMS, including those in company premises or elsewhere in India or abroad.\n",
      "4. **Definition of Employee**: An employee of BBIL SYSTEMS includes anyone carrying out work on behalf of the company, regardless of their employment status or basis.\n",
      "\n",
      "Additionally, the policy aims to adopt a zero-tolerance attitude towards any kind of sexual harassment or discrimination caused by any employee during their tenure in BBIL SYSTEMS towards any other person, including employees, clients, vendors, and contractors.\n",
      "\n",
      "Note that the provided context only includes the policy guidelines and does not specify the detailed procedures or actions to be taken in case of a complaint or incident.\n",
      "\n",
      "Sources:\n",
      "- posh-policy.pdf\n",
      "- posh-policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  How many Earned Leaves do I get in one year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You Asked:\n",
      "How many Earned Leaves do I get in one year\n",
      "\n",
      "Answer:\n",
      "The text doesn't explicitly state the number of Earned Leaves you get in one year. However, it does mention that if you are unable to use all of your accrued Earned Leave during a calendar year, you may elect to carry forward any accrued but unused Earned Leave into the next calendar year, subject to the maximum leave of 45 days. This suggests that the maximum Earned Leave you can accrue in a year is 45 days.\n",
      "\n",
      "Sources:\n",
      "- Leave-Policy.pdf\n",
      "- Leave-Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What is casual leave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You Asked:\n",
      "What is casual leave\n",
      "\n",
      "Answer:\n",
      "Casual leave is a type of leave that an employee can take for personal or miscellaneous reasons, such as a family event, a personal appointment, or a sudden need to attend to a personal matter. It is usually taken on short notice and is not related to illness or injury.\n",
      "\n",
      "Sources:\n",
      "- Leave-Policy.pdf\n",
      "- Leave-Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What do you mean by Scope and purpose\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You Asked:\n",
      "What do you mean by Scope and purpose\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, it appears that the \"Scope\" and \"Purpose\" refer to the definition of the scope and purpose of the information disclosure, likely related to IEnova's business relationships and affiliations.\n",
      "\n",
      "The scope seems to include:\n",
      "\n",
      "- Individuals mentioned in conditions a) to c) (though these conditions are not explicitly stated in the provided text)\n",
      "- Partners or co-owners of the individuals mentioned in conditions a) to c)\n",
      "- Companies that are part of a business group or consortium to which IEnova belongs\n",
      "- Companies over which one of the individuals referenced by conditions a) to c) have control or significant influence\n",
      "\n",
      "The purpose of this scope is not explicitly stated in the provided text, but it is likely related to transparency and disclosure of IEnova's business relationships and affiliations, possibly for regulatory or compliance purposes.\n",
      "\n",
      "Sources:\n",
      "- Salary_Policy.pdf\n",
      "- Salary_Policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  Can you describe the scope and functions in depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You Asked:\n",
      "Can you describe the scope and functions in depth\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, the POSH Policy guidelines for BBIL SYSTEMS aim to create and maintain a safe work environment that is free from sexual harassment and discrimination. Here's a detailed explanation of the scope and functions of the POSH Policy guidelines:\n",
      "\n",
      "**Scope:**\n",
      "\n",
      "The POSH Policy guidelines apply to all employees of BBIL SYSTEMS, including:\n",
      "\n",
      "* Permanent employees\n",
      "* Temporary employees\n",
      "* Contracted employees\n",
      "* Employees on a retainer ship basis\n",
      "* Employees on a part-time basis\n",
      "* Employees hired directly or indirectly\n",
      "* Employees hired through vendor organizations\n",
      "\n",
      "The scope also extends to clients, vendors, and contractors in company premises or elsewhere in India or abroad.\n",
      "\n",
      "**Functions:**\n",
      "\n",
      "The POSH Policy guidelines aim to:\n",
      "\n",
      "1. **Create a safe work environment**: The policy aims to create a work environment that is free from sexual harassment and discrimination, where all employees feel safe and respected.\n",
      "2. **Establish guidelines**: The policy establishes guidelines as per the guidelines of \"The Sexual harassment of women at workplace (prevention, prohibition & redressal) Act, 2013\".\n",
      "3. **Adopt zero tolerance attitude**: BBIL SYSTEMS adopts a zero-tolerance attitude towards any kind of sexual harassment or discrimination caused by any employee during their tenure in BBIL SYSTEMS.\n",
      "4. **Prevent and prohibit sexual harassment**: The policy aims to prevent and prohibit sexual harassment and discrimination in all its forms, including:\n",
      "\t* Physical harassment\n",
      "\t* Verbal harassment\n",
      "\t* Non-verbal harassment\n",
      "\t* Sexual harassment\n",
      "\t* Discrimination\n",
      "5. **Provide redressal mechanism**: The policy provides a redressal mechanism for employees who experience or witness sexual harassment or discrimination, including:\n",
      "\t* Reporting incidents\n",
      "\t* Investigation and inquiry\n",
      "\t* Disciplinary action against perpetrators\n",
      "\t* Support and counseling for victims\n",
      "6. **Promote awareness and education**: The policy aims to promote awareness and education among employees about the importance of maintaining a safe and respectful work environment.\n",
      "\n",
      "Overall, the POSH Policy guidelines for BBIL SYSTEMS aim to create a culture of respect, dignity, and inclusivity, where all employees feel valued and supported.\n",
      "\n",
      "Sources:\n",
      "- posh-policy.pdf\n",
      "- posh-policy.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in (\"exit\", \"quit\"):\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        result = qa_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "        answer = result[\"answer\"]\n",
    "        sources = result[\"source_documents\"]\n",
    "\n",
    "        print(\"\\nYou Asked:\")\n",
    "        print(query)\n",
    "\n",
    "        print(\"\\nAnswer:\")\n",
    "        print(answer)\n",
    "\n",
    "        print(\"\\nSources:\")\n",
    "        for src in sources:\n",
    "            print(f\"- {src.metadata.get('source')}\")\n",
    "\n",
    "        # Update chat history\n",
    "        chat_history.append((query, answer))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5555e-c559-4d3a-a864-cf6c008b4321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
