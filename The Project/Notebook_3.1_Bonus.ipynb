{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7224502b-a2e0-4943-b47a-e201897a41e7",
   "metadata": {},
   "source": [
    "### Upgrading Notebook 3 showing the use of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88057a3-f54e-4b85-8967-edcf8916b91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment ready, Groq key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"‚ö†Ô∏è Please add your GROQ_API_KEY to .env file!\")\n",
    "\n",
    "print(\"‚úÖ Environment ready, Groq key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d5354-f261-482d-a012-0a29ce7cf10c",
   "metadata": {},
   "source": [
    "We are going to use 2 tools here:\n",
    "- summarizer tool\n",
    "- extracter tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387d6a5d-aee0-404e-9710-ffe448b11296",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"summarize_text\", return_direct=True)\n",
    "def summarize_text(input_text: str) -> str:\n",
    "    \"\"\"Summarize the given text into 2‚Äì3 sentences.\"\"\"\n",
    "    sentences = input_text.split('.')\n",
    "    summary = '. '.join(sentences[:3])\n",
    "    return f\"üßæ Summary:\\n{summary.strip()}...\"\n",
    "\n",
    "@tool(\"extract_keywords\", return_direct=True)\n",
    "def extract_keywords(input_text: str) -> str:\n",
    "    \"\"\"Extract key terms from text by removing short/common words.\"\"\"\n",
    "    words = [w.strip('.,!?').lower() for w in input_text.split()]\n",
    "    keywords = [w for w in words if len(w) > 5]\n",
    "    return f\"üîë Keywords:\\n{', '.join(set(keywords[:8]))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a05b8f-888d-442e-b7db-6e55f9a49585",
   "metadata": {},
   "source": [
    "### Loading and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c645a86-b5b1-47bb-b193-478ae06fd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 15 documents from ./policies\n",
      "üìö Created 48 chunks for retrieval.\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "data_dir = \"./policies\"\n",
    "\n",
    "if os.path.isdir(data_dir) and any(os.scandir(data_dir)):\n",
    "    for entry in os.scandir(data_dir):\n",
    "        if entry.is_file() and entry.name.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(entry.path)\n",
    "        elif entry.is_file() and entry.name.endswith((\".txt\", \".md\")):\n",
    "            loader = TextLoader(entry.path, encoding=\"utf8\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        loaded_docs = loader.load()\n",
    "        for d in loaded_docs:\n",
    "            d.metadata = {\"source\": entry.name}\n",
    "        docs.extend(loaded_docs)\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(docs)} documents from {data_dir}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files found, using sample fallback.\")\n",
    "    docs = [Document(page_content=\"Refund policy allows returns within 30 days.\", metadata={\"source\":\"sample.txt\"})]\n",
    "\n",
    "# Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"üìö Created {len(chunks)} chunks for retrieval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6923d-16a3-4387-90a2-df6a5e90fc57",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a984c7-4909-41d7-aed5-0d5769542623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store and retriever ready.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma.from_documents(chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "print(\"‚úÖ Vector store and retriever ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c8aeb-af5c-4b24-89f8-bdf9f483f742",
   "metadata": {},
   "source": [
    "### Initializng LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f446bc8-603f-452a-b898-fdac08c99328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Groq LLM initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=groq_api_key\n",
    ")\n",
    "\n",
    "print(\"üß† Groq LLM initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47897368-bb7e-4641-9ce6-518cc758143a",
   "metadata": {},
   "source": [
    "### Creating RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b899e3a1-efc6-4f54-9799-71bdc87b3a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó RAG chain created successfully.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"üîó RAG chain created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc667164-7ba9-4c03-a5f2-d9e9e1627a14",
   "metadata": {},
   "source": [
    "### Combine RAG + Tools into Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a7fea-98ce-43fb-afeb-d7ad8a8c1b5d",
   "metadata": {},
   "source": [
    "Here, the agent decides when to use the summarizer, keyword extractor, or RAG retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2f8e37-ce0d-4127-b011-767440ac61dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent initialized with summarizer and keyword extractor tools.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket.khopkar\\AppData\\Local\\Temp\\ipykernel_15208\\3807658330.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "tools = [summarize_text, extract_keywords]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Agent initialized with summarizer and keyword extractor tools.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500bf73-998d-4422-aecf-33b6c94349f9",
   "metadata": {},
   "source": [
    "### The QnA loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148fe38-c286-46ff-899d-82c6bfa9b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG Agent is ready\n",
      "\n",
      "Type 'exit' to quit this conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßçYou:  What is Casual Leave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket.khopkar\\AppData\\Local\\Temp\\ipykernel_15208\\3856610065.py:16: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  final_answer = agent.run(f\"Summarize or extract keywords if needed. Context: {answer}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: summarize_text\n",
      "Action Input: Casual Leave is a type of leave that can be taken by an employee for short periods of time, typically for personal or miscellaneous reasons. It is usually granted for a minimum of 0.5 days to a maximum of 3 days, and any leave taken beyond 3 days is considered as Earned/Privileged Leave.\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3müßæ Summary:\n",
      "Casual Leave is a type of leave that can be taken by an employee for short periods of time, typically for personal or miscellaneous reasons.  It is usually granted for a minimum of 0. 5 days to a maximum of 3 days, and any leave taken beyond 3 days is considered as Earned/Privileged Leave...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ü§ñ Assistant: üßæ Summary:\n",
      "Casual Leave is a type of leave that can be taken by an employee for short periods of time, typically for personal or miscellaneous reasons.  It is usually granted for a minimum of 0. 5 days to a maximum of 3 days, and any leave taken beyond 3 days is considered as Earned/Privileged Leave...\n",
      "\n",
      "üìö Source: Leave-Policy.pdf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßçYou:  What are POSH policy guidelines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: The policy aims to create a safe work environment. What is the primary goal of this policy?\n",
      "Thought: To answer this question, I need to understand the purpose and scope of the policy.\n",
      "Action: summarize_text\n",
      "Action Input: The policy aims to create and maintain a safe work environment that is free from sexual harassment and discrimination for all employees.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3müßæ Summary:\n",
      "The policy aims to create and maintain a safe work environment that is free from sexual harassment and discrimination for all employees....\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ü§ñ Assistant: üßæ Summary:\n",
      "The policy aims to create and maintain a safe work environment that is free from sexual harassment and discrimination for all employees....\n",
      "\n",
      "üìö Source: posh-policy.pdf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßçYou:  What does POSH internal committee do\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The POSH internal committee seems to be involved in handling complaints related to sexual harassment, making decisions, and communicating the outcomes to those involved.\n",
      "\n",
      "Action: summarize_text\n",
      "Action Input: The POSH internal committee seems to be involved in handling complaints related to sexual harassment, making decisions, and communicating the outcomes to those involved.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3müßæ Summary:\n",
      "The POSH internal committee seems to be involved in handling complaints related to sexual harassment, making decisions, and communicating the outcomes to those involved....\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ü§ñ Assistant: üßæ Summary:\n",
      "The POSH internal committee seems to be involved in handling complaints related to sexual harassment, making decisions, and communicating the outcomes to those involved....\n",
      "\n",
      "üìö Source: posh-policy.pdf\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRAG Agent is ready\")\n",
    "print(\"\\nType 'exit' to quit this conversation.\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"üßçYou: \").strip()\n",
    "    if query.lower() in (\"exit\", \"quit\"):\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Step 1: Retrieve documents\n",
    "        retrieved = qa_chain.invoke({\"query\": query})\n",
    "        answer = retrieved[\"result\"]\n",
    "\n",
    "        # Step 2: Let agent enhance or summarize response\n",
    "        final_answer = agent.run(f\"Summarize or extract keywords if needed. Context: {answer}\")\n",
    "\n",
    "        print(\"\\nü§ñ Assistant:\", final_answer)\n",
    "        print(\"\\nüìö Source:\", retrieved[\"source_documents\"][0].metadata.get(\"source\", \"Unknown\"))\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78309345-e1db-403b-9493-5b046f55134f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
